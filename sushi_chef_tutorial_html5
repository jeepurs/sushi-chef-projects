import requests
import tempfile
from bs4 import BeautifulSoup

from ricecooker.classes.nodes import ChannelNode, HTML5AppNode, TopicNode
from ricecooker.classes.files import HTMLZipFile, ThumbnailFile
from ricecooker.utils.caching import CacheForeverHeuristic, FileCache, CacheControlAdapter, InvalidatingCacheControlAdapter

from ricecooker.utils.html import download_file
from ricecooker.utils.zip import create_predictable_zip

from ricecooker.classes import licenses


sess = requests.Session()
cache = FileCache('.webcache')
basic_adapter = CacheControlAdapter(cache=cache)
forever_adapter= CacheControlAdapter(heuristic=CacheForeverHeuristic(), cache=cache)

sess.mount('http://', forever_adapter)
sess.mount('https://', forever_adapter)

def make_fully_qualified_url(url):
    if url.startswith("//"):
        return "https:" + url
    if url.startswith("/"):
        return "https://open.edu" + url
    assert url.startswith("http"), "Bad URL (relative to unknown location): " + url
    return url

def make_request(url, *args, **kwargs):
    response = sess.get(url, *args, **kwargs)
    if response.status_code != 200:
        print("NOT FOUND:", url)
    elif not response.from_cache:
        print("NOT CACHED:", url)
    return response

def get_parsed_html_from_url(url, *args, **kwargs):
    html = make_request(url, *args, **kwargs).content
    return BeautifulSoup(html, "html.parser")

def construct_channel(*args, **kwargs):

    channel = ChannelNode(
        source_domain="open.edu",
        source_id="2042",
        title="TESSA English",
        thumbnail="http://www.open.edu/openlearncreate/pluginfile.php/136593/coursecat/description/tessa_logo_resized%20for%20OLC.jpg",
    )

    primary_topic = TopicNode(source_id="List_of_primary", title="Primary")
    channel.add_child(primary_topic)
    add_subpages_from_wikipedia_list(primary_topic, "http://www.open.edu/openlearncreate/mod/oucontent/view.php?id=81683")
    #single page view: http://www.open.edu/openlearncreate/mod/oucontent/view.php?id=81683&printable=1

    secondary_topic = TopicNode(source_id="List_of_secondary", title="Secondary")
    channel.add_child(secondary_topic)
    add_subpages_from_wikipedia_list(secondary_topic, "http://www.open.edu/openlearncreate/mod/oucontent/view.php?id=81698")
    #single page view: http://www.open.edu/openlearncreate/mod/oucontent/view.php?id=81698&printable=1

    return channel

    #http://www.open.edu/openlearncreate/mod/oucontent/coursedownloads.php?course=2042&type=html

def add_subpages_from_wikipedia_list(topic, list_url):

    # to understand how the following parsing works, look at:
    #   1. the source of the page or inspect in chrome dev tools
    #   2. the documentation for BeautifulSoup version 4: https://www.crummy.com/software/BeautifulSoup/bs4/doc/

    # parse the the page into BeautifulSoup format, so we can loop through and manipulate it
    page = get_parsed_html_from_url(list_url)

    # extract the table of contents from the page
    table = page.find("table")

    # loop through all the rows in the table
    for row in table.find_all("tr"):

        # extract the columns (cells, really) within the current row
        columns = row.find_all("td")

        # some rows are empty, so just skip
        if not columns:
            continue

        # get the link to the subpage
        link = columns[0].find("a")

        # some rows don't have links, so skip
        if not link:
            continue

        # extract the URL and title for the subpage
        url = make_fully_qualified_url(link["href"])
        title = link.text

        # attempt to extract a thumbnail for the subpage, from the second column in the table
        image = columns[1].find("img")
        thumbnail_url = make_fully_qualified_url(image["src"]) if image else None
        if thumbnail_url and not (thumbnail_url.endswith("jpg") or thumbnail_url.endswith("png")):
            thumbnail_url = None

        # download the wikipedia page into an HTML5 app node
        html5app = download_wikipedia_page(url, thumbnail=thumbnail_url, title=title)

        # add the downloaded HTML5 app node into the topic
        topic.add_child(html5app)


def download_wikipedia_page(url, thumbnail, title):

    # create a temp directory to house our downloaded files
    destpath = tempfile.mkdtemp()

    # downlod the main wikipedia page, apply a middleware processor, and call it index.html
    localref, _ = download_file(
        url,
        destpath,
        filename="index.html",
        middleware_callbacks=process_wikipedia_page,
        request_fn=make_request,
    )

    # turn the temp folder into a zip file
    zippath = create_predictable_zip(destpath)

    # create an HTML5 app node
    html5app = HTML5AppNode(
        files=[HTMLZipFile(zippath)],
        title=title,
        thumbnail=thumbnail,
        source_id=url.split("/")[-1],
        license=licenses.PublicDomainLicense(),
        #CC_BY_NC_SA for TESSA
    )

    return html5app


def process_wikipedia_page(content, baseurl, destpath, **kwargs):

    page = BeautifulSoup(content, "html.parser")

    for image in page.find_all("img"):
        relpath, _ = download_file(make_fully_qualified_url(image["src"]), destpath, request_fn=make_request)
        image["src"] = relpath

    return str(page)